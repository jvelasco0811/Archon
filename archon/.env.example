# LLM Provider Configuration
LLM_PROVIDER=Bedrock  # Options: 'OpenAI', 'Bedrock', 'Anthropic', 'Ollama'
BASE_URL=

# Bedrock Configuration
AWS_ACCESS_KEY_ID=  # Your AWS access key
AWS_SECRET_ACCESS_KEY=  # Your AWS secret key
AWS_SESSION_TOKEN=  # Your AWS session token (if using temporary credentials)
AWS_REGION=us-east-1  # Your AWS region
AWS_PROFILE=jaime.dev  # Optional: Your AWS profile name if using AWS CLI profiles
LLM_API_KEY=  # Your API key if required

# Embedding Configuration
EMBEDDING_PROVIDER=Bedrock  # Options: 'OpenAI' or 'Bedrock'
EMBEDDING_MODEL=amazon.titan-embed-text-v2:0  # For Bedrock: amazon.titan-embed-text-v2:0, For OpenAI: text-embedding-3-small

# Model Configuration
REASONER_MODEL=  # The LLM for reasoning tasks
PRIMARY_MODEL=  # The LLM for primary agent/coder tasks